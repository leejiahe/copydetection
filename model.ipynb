{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import einops\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torchmetrics import MaxMetric\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "from transformers import ViTModel\n",
    "\n",
    "from src.models.components.layers import CopyDetectEmbedding, NormalizedFeatures, SimImagePred, ContrastiveProj\n",
    "from src.datamodules.copydetect_datamodule import CopyDetectDataModule\n",
    "from src.datamodules.components.augmentation import Augment\n",
    "from src.utils.nt_xent_loss import NTXentLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_path = lambda x: os.path.join(os.getcwd(),'data', x)\n",
    "\n",
    "augment = Augment(overlay_image_dir = get_path('train/'),\n",
    "                  n_upper = 2,\n",
    "                  n_lower = 1)\n",
    "ntxentloss = NTXentLoss(temperature = 0.9, eps = 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CopyDetectModule(LightningModule):\n",
    "    def __init__(self,\n",
    "                 pretrained_arch: str,          # Pretrained ViT architecture\n",
    "                 ntxentloss: object,            # Contrastive loss\n",
    "                 hidden_dim: int = 2048,        # Contrastive projection size of hidden layer\n",
    "                 projected_dim: int = 512,      # Contrastive projection size of projection head \n",
    "                 beta1: int = 1,                # Similar image BCE loss multiplier\n",
    "                 beta2: int = 1,                # Contrastive loss multiplier\n",
    "                 lr: float = 0.001,\n",
    "                 weight_decay: float = 0.0005):               \n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(logger = False)\n",
    "        #! Change all this to hparams\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "         \n",
    "        # Instantiate ViT encoder from pretrained model\n",
    "        pretrained_model = ViTModel.from_pretrained(pretrained_arch)\n",
    "        encoder = pretrained_model.encoder\n",
    "                \n",
    "        # Instantiate embedding, we use the pretrained ViT cls and position embedding\n",
    "        embedding = CopyDetectEmbedding(config = pretrained_model.config,\n",
    "                                        vit_cls = pretrained_model.embeddings.cls_token,\n",
    "                                        pos_emb = pretrained_model.embeddings.position_embeddings)\n",
    "        \n",
    "        # Normalized features\n",
    "        normfeats = NormalizedFeatures(hidden_dim = pretrained_model.config.hidden_size,\n",
    "                                       layer_norm_eps = pretrained_model.config.layer_norm_eps)\n",
    "        # Feature Vector Extractor\n",
    "        self.feature_extractor = nn.Sequential(embedding, encoder, normfeats)\n",
    "        \n",
    "        # Instantiate SimImagePredictor\n",
    "        simimagepred = SimImagePred(embedding_dim = pretrained_model.config.hidden_size)\n",
    "        self.embedding = embedding\n",
    "        self.simimagepred = nn.Sequential(encoder, normfeats, simimagepred)\n",
    "\n",
    "        \n",
    "        # Instantiate ContrastiveProjection\n",
    "        contrastiveproj = ContrastiveProj(embedding_dim = pretrained_model.config.hidden_size,\n",
    "                                          hidden_dim = hidden_dim,\n",
    "                                          projected_dim = projected_dim)\n",
    "        self.contrastiveproj = nn.Sequential(embedding, encoder, normfeats, contrastiveproj)\n",
    "        \n",
    "        # Contrastive loss \n",
    "        self.contrastive_loss = ntxentloss\n",
    "        \n",
    "        # Binary cross entropy loss for similar image pair\n",
    "        self.bce_loss = torch.nn.BCEWithLogitsLoss()\n",
    "        # Model accuracy in detecting modified copy\n",
    "        self.train_acc, self.val_acc = Accuracy(), Accuracy()     \n",
    "        # For logging best validation accuracy\n",
    "        self.val_acc_best = MaxMetric()\n",
    "\n",
    "    def forward(self,\n",
    "                img_r: torch.Tensor,\n",
    "                img_q: Optional[torch.Tensor] = None,\n",
    "                ) -> torch.Tensor:\n",
    "        if img_q is not None:\n",
    "            return self.feature_extractor(img_r)\n",
    "        else:\n",
    "            embedding_rq = self.embedding(img_r, img_q)\n",
    "            logits = self.simimagepred(embedding_rq)\n",
    "            preds = torch.argmax(logits, dim = 1)\n",
    "            return preds\n",
    "\n",
    "    def step(self, img_r: List[torch.Tensor], img_q: List[torch.Tensor], label: List[torch.Tensor], val: Optional[bool] = False):\n",
    "        # img_r, img_q to SimImagePredictor\n",
    "        embedding_rq = self.embedding(img_r, img_q) ## nn sequential don't take multiple input\n",
    "        logits = self.simimagepred(embedding_rq)\n",
    "        # Calculate binary cross entropy loss of similar image pair\n",
    "        simimage_loss = self.bce_loss(logits, label.unsqueeze(dim = 1))\n",
    "        # Predictions\n",
    "        preds = torch.argmax(logits, dim = 1)\n",
    "        \n",
    "        # Get positive indices\n",
    "        pos_indices = label.bool()\n",
    "        # Forward positive indices of img_r and img_q to ContrastiveProjection\n",
    "        proj_r = self.contrastiveproj(img_r[pos_indices])\n",
    "        proj_q = self.contrastiveproj(img_q[pos_indices])\n",
    "\n",
    "        # Calculate contrastive loss between un-augmented img_r and augmented positive pair of img_q\n",
    "        contrastive_loss = self.contrastive_loss(proj_r, proj_q)\n",
    "        \n",
    "        # Weighted sum of bce and contrastive loss\n",
    "        total_loss = self.beta1 * simimage_loss + self.beta2 * contrastive_loss\n",
    "        \n",
    "        return {'simimage': simimage_loss, 'contrastive': contrastive_loss, 'total': total_loss}, preds\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int):\n",
    "        img_r, img_q, label = batch\n",
    "        img_r, img_q, label = torch.vstack(img_r), torch.vstack(img_q), torch.hstack(label)\n",
    "\n",
    "        losses, preds = self.step(img_r, img_q, label)\n",
    "        \n",
    "        # Log train metrics\n",
    "        acc = self.train_acc(preds, label.int())\n",
    "        self.log(\"train/total_loss\", losses['total'], on_step = True, on_epoch = True, prog_bar = False)\n",
    "        self.log(\"train/simimage_loss\", losses['simimage'], on_step = True, on_epoch = True, prog_bar = False)\n",
    "        self.log(\"train/contrastive_loss\", losses['contrastive'], on_step = True, on_epoch = True, prog_bar = False)\n",
    "        self.log(\"train/acc\", acc, on_step = True, on_epoch = True, prog_bar = True)\n",
    "\n",
    "        return losses['total']\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int):\n",
    "        img_r, img_q, label = batch\n",
    "        losses, preds = self.step(img_r, img_q, label, val = True)\n",
    "\n",
    "        # Log val metrics\n",
    "        acc = self.val_acc(preds, label.int())\n",
    "        self.log(\"val/total_loss\", losses['total'], on_step = True, on_epoch = True, prog_bar = False)\n",
    "        self.log(\"val/simimage_loss\", losses['simimage'], on_step = True, on_epoch = True, prog_bar = False)\n",
    "        self.log(\"val/contrastive_loss\", losses['contrastive'], on_step = True, on_epoch = True, prog_bar = False)\n",
    "        self.log(\"val/acc\", acc, on_step = True, on_epoch = True, prog_bar = True)\n",
    "\n",
    "        return losses['total']\n",
    "\n",
    "    def validation_epoch_end(self, outputs: Any):\n",
    "        acc = self.val_acc.compute()  # get val accuracy from current epoch\n",
    "        self.val_acc_best.update(acc)\n",
    "        self.log(\"val/acc_best\", self.val_acc_best.compute(), on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Reset metrics at the end of every epoch\n",
    "        self.train_acc.reset()\n",
    "        self.val_acc.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(\n",
    "            params = self.parameters(), lr = self.lr, weight_decay = self.weight_decay\n",
    "        )\n",
    "\n",
    "pretrained_arch = 'google/vit-base-patch16-224'\n",
    "\n",
    "model = CopyDetectModule(pretrained_arch, ntxentloss)\n",
    "\n",
    "datamodule = CopyDetectDataModule(train_dir = get_path('train/'),\n",
    "                           references_dir = get_path('references/'),\n",
    "                           dev_queries_dir = get_path('dev_queries/'),\n",
    "                           final_queries_dir = get_path('final_queries/'),\n",
    "                           augment = augment,\n",
    "                           dev_validation_set = get_path('dev_validation_set.csv'),\n",
    "                           batch_size = 16,\n",
    "                           pin_memory = True,\n",
    "                           num_workers = 10,\n",
    "                           n_crops = 2\n",
    "                           )\n",
    "\n",
    "datamodule.setup()\n",
    "\n",
    "trainer = Trainer(fast_dev_run =  True)\n",
    "trainer.fit(model = model, datamodule = datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = CopyDetectDataModule(train_dir = get_path('train/'),\n",
    "                           references_dir = get_path('references/'),\n",
    "                           dev_queries_dir = get_path('dev_queries/'),\n",
    "                           final_queries_dir = get_path('final_queries/'),\n",
    "                           augment = augment,\n",
    "                           dev_validation_set = get_path('dev_validation_set.csv'),\n",
    "                           batch_size = 16,\n",
    "                           pin_memory = True,\n",
    "                           num_workers = 10,\n",
    "                           n_crops = 2\n",
    "                           )\n",
    "\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(datamodule.test_dataloader())).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "496e6ccc940d7baf27126816b5de78ce76f9b9d17be85a2d2d9dfc63004cf58f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cama')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
